> 1. In your own words, explain the benefits of normalization. Include a real-world scenario where normalization is necessary.

In my younger database career, I would've designed a database table that would've had all of a persons information in it such as address, phone number, email and so on.  If you were to take a table like that and divide it up to where the persons information specific to that person was in one table, you would keep first, middle and last name.  You could also include an SSN if you absolutely have to collect that type of a data and a birthdate and maybe even name prefix and suffix. One other field could be a designation like PhD, JD etc.  In a second table you could make it an address table that only includes address information and possibly what type of address it might be categorized as. In another table you could make it a phone number table and again give it a categorization. Splitting data up like this is the process of normalization.

In a hospital, you'd want to normalize patients medical data because of the amount of data being collected at the same time. If you have medical personnel trying to look up data on people that are currently inpatients at the same time that other medical personnel are trying to input more data, that could cause a lot of performance problems if the database isn't designed right.

> 2. List and explain the different normal forms and how they relate to one another, with regard to your real-world scenario in the first question.

1NF = To keep things simple, let's take the first name of a patient with 2 diagnosis codes. In order to have 1NF, you would have to have one name in each field in the name column and one diagnosis code in the other field or column.

Not 1NF...
|Name   |DX CODE      |
|-------|:-----------:|
|Joe    |V76.2 Z12.4  |

This does meet the 1NF definition...
|Name   |DX CODE      |
|-------|:-----------:|
|Joe    |V76.2        |
|Joe    |Z12.4        |

2NF = To analyze if a table is in 2NF, it has to be determined that the table is first in 1NF. The next rule is *all non-key attributes can't be dependent on a subset of the primary key.*

Not 2NF...
|Name   |DX CODE  |AGE  |
|-------|:-------:|----:|
|Joe    |V76.2    |65   |

Meets 2NF requirements

*Name*
|Name   |Age      |
|-------|:-------:|
|Joe    |65       |

*ICD10*
|Name   |DX CODE  |
|-------|:-------:|
|Joe    |V76.2    |

3NF = The first rule is that it must meet 2NF requirements. Then *All transitive functional dependencies of non-prime attributes must not exist.* In the example below, this does not meet 3NF reqs because City and State do not depend on the existence of the patient.

|Name   |Age  |City       |State |
|-------|:---:|----------:|-----:|
|Joe    |65   |Aurora     |CO    |

This next example does meet 3NF reqs because we split the information into 2 tables

*Name*
|Name   |Age  |address_id|
|-------|:---:|---------:|
|Joe    |65   |549       |

*Address*
|address_id|City |State |
|----------|:-----:|---:|
|549       |Aurora |CO  |

> 3. This [student_records](https://www.db-fiddle.com/f/kwVrsocvpqgfS1gNkAP51T/0) table contains students and their grades in different subjects. The schema is already in first normal form (1NF). Convert this schema to the third normal form (3NF) using the techniques you learned in this checkpoint.

I'd prefer to make a name instead of 2 tables containing professors and students but got stuck in a few places. I also dumped the ID column from the original script because it seemed monotonous.

Here's the scripting I created to make it 3NF...

```
-- Create students table
CREATE TABLE students (
  "student_id"     	  INTEGER
  ,"student_email"  	VARCHAR(24)
  ,"student_name"   	VARCHAR(9)
);

-- Populate students table.
INSERT INTO students
  ("student_id", "student_email", "student_name")
VALUES
	 (1, 'john.b20@hogwarts.edu', 'John B')
  ,(2, 'sarah.s20@hogwarts.edu', 'Sarah S')
  ,(3, 'martha.l20@hogwarts.edu',  'Martha L')
  ,(4, 'james.g20@hogwarts.edu', 'James G')
  ,(5, 'stanley.p20@hogwarts.edu', 'Stanley P');


-- Create classes table
CREATE TABLE classes (
  "class_id"     	INTEGER
  ,"class_title"	VARCHAR(30)
);

-- Populate classes table
INSERT INTO classes
  ("class_id", "class_title")
VALUES
	 (1, 'Philosophy')
  ,(2, 'Economics')
  ,(3, 'Mathematics');


-- Create professors table
CREATE TABLE professors (
  "professor_id"     	INTEGER
  ,"professor_name"		VARCHAR(30)
);

-- Populate professors table
INSERT INTO professors
  ("professor_id", "professor_name")
VALUES
	 (4, 'William C')
  ,(5, 'Natalie M')
  ,(6, 'Mark W');


-- Create enrollment table
CREATE TABLE enrollment (
  "semester_id"		INTEGER
  ,"class_id" 		INTEGER
  ,"student_id" 	INTEGER
  ,"professor_id"	INTEGER
  ,"grade"		  	VARCHAR(1)
);

-- Populate enrollment table
INSERT INTO enrollment
  ("semester_id", "class_id", "student_id", "professor_id", "grade")
VALUES
	 (1, 1, 1, 4, 'A')
  ,(1, 1, 2, 4, 'C')
  ,(1, 2, 3, 5, 'A')
  ,(1, 3, 4, 6, 'B')
  ,(1, 2, 5, 5, 'B');
```

> 4. In your own words, explain the potential disadvantages of normalizing the data above. What are its trade-offs? Submit your findings in the submission table and discuss them with your mentor in your next session.

For reporting purposes, it would make it so that writing scripts is harder to do.  Also if you have many people trying to run summary reports, it could seriously degrade the performance of the server. It could also affect data integrity if it's not done right. The trade off is that you get really good performance for the people using the application keying in data.

> 5. Looking at the tables you have normalized. If you need to denormalize to improve query performance or speed up reporting, how would you carry out denormalization for this database design? Submit potential strategies in the submission tab and discuss them with your mentor in your next session.

First, I wouldn't guess what data would be most often needed for reporting.  I'd find out if there are any regulatory reporting needs to any sort of governing body or government agency to find out what is needed there.  I would then find out what are common KPI's of the industry that is using the data. At that point, I would ask senior and middle management what type of reporting needs they would require. At that point I would sit down and plan out how to denormalize the data. I may create a few more tables that could be considered snapshots or a mini data warehouse where a nightly script runs and populates those denormalized tables and tag each record with a date or a time period integer.

> 6. Explore the trade-offs between data normalization and denormalization in this scenario, submit your findings in the submission tab, and discuss them with your mentor in your next session.

In a nutshell, data normalization is awesome for apps and data entry but takes a performance hit if you're doing ad hoc reporting.  The further you go down (from 1NF to 3NF) the performance gets worse. Denormalization is ideal for ad hoc reporting but if you design your tables for your apps this way, it would take a hit in performance. Like I said in the last sentence, reporting performance would be great. 
